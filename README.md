# Galio - Spanish Government Bulletin Web Scraper

Sistema automatizado de scraping para extraer informaciÃ³n de subvenciones, licitaciones y contratos de boletines oficiales espaÃ±oles nacionales y regionales.

## DescripciÃ³n del Proyecto

Galio es un proyecto Django que implementa un sistema de web scraping que monitorea mÃºltiples boletines oficiales espaÃ±oles para extraer automÃ¡ticamente informaciÃ³n relevante sobre subvenciones, licitaciones y contratos pÃºblicos. El sistema soporta tanto el BOE nacional como boletines regionales de CataluÃ±a, Valencia, Madrid, Asturias y Barcelona.

## Diagrama UML de Arquitectura

```mermaid
classDiagram
    class ScrapedItem {
        +AutoField id
        +URLField url_base
        +TextField title
        +URLField link
        +URLField pdf_url
        +DateTimeField created_at
        +CharField region
        +CharField organism
        +REGION_CHOICES
        +ORGANISM_CHOICES
    }
    
    class ScrapingOrchestrator {
        +scrape_multiple_websites(urls, keywords)
        +get_boe_url()
        +get_dogc_url()
        +get_bocm_url()
    }
    
    class BOEService {
        +scrape_boe(driver, url, keywords)
        -extract_sumario()
        -filter_by_keywords()
    }
    
    class DOGCService {
        +scrape_dogc(driver, url, keywords)
        -extract_destacat_content()
        -filter_by_keywords()
    }
    
    class DOGVService {
        +scrape_dogv(driver, url, keywords)
        -navigate_iframes()
        -extract_iframe_content()
    }
    
    class BOCMService {
        +scrape_bocm(driver, url, keywords)
        -extract_parallel_data()
        -match_titles_pdfs()
    }
    
    class BOPAService {
        +scrape_bopa(driver, url, keywords)
        -process_definition_lists()
        -extract_pdf_links()
    }
    
    class BOPDIBAService {
        +scrape_bopdiba(driver, url, keywords)
        -navigate_subpages()
        -extract_pdf_downloads()
    }
    
    class HolidayService {
        +get_holidays(year, region)
        +get_madrid_holidays(year)
        +get_catalonia_holidays(year)
        +get_spain_holidays(year)
    }
    
    class APIView {
        +scraped_items(request)
        -apply_filters()
        -return_json_response()
    }
    
    class ManagementCommand {
        +handle()
        -execute_scraping()
        -save_to_database()
    }
    
    ScrapingOrchestrator --> BOEService
    ScrapingOrchestrator --> DOGCService
    ScrapingOrchestrator --> DOGVService
    ScrapingOrchestrator --> BOCMService
    ScrapingOrchestrator --> BOPAService
    ScrapingOrchestrator --> BOPDIBAService
    ScrapingOrchestrator --> HolidayService
    
    BOEService --> ScrapedItem
    DOGCService --> ScrapedItem
    DOGVService --> ScrapedItem
    BOCMService --> ScrapedItem
    BOPAService --> ScrapedItem
    BOPDIBAService --> ScrapedItem
    
    APIView --> ScrapedItem
    ManagementCommand --> ScrapingOrchestrator
    ManagementCommand --> ScrapedItem
```

## Diagrama de Flujo del Sistema

```mermaid
flowchart TD
    START["ğŸš€ Inicio de Galio"] --> COMMAND["python manage.py scrape"]
    
    COMMAND --> ORCHESTRATOR["scrape_multiple_websites()"]
    
    ORCHESTRATOR --> URL_GEN["GeneraciÃ³n de URLs"]
    
    subgraph "GeneraciÃ³n Inteligente de URLs"
        URL_GEN --> BOE_URL["get_boe_url()"]
        URL_GEN --> DOGC_URL["get_dogc_url()"]
        URL_GEN --> BOCM_URL["get_bocm_url()"]
        URL_GEN --> STATIC_URLS["URLs EstÃ¡ticas<br/>(DOGV, BOPA, BOP DIBA)"]
        
        BOE_URL --> HOLIDAYS1["Verificar festivos EspaÃ±a"]
        DOGC_URL --> HOLIDAYS2["Verificar festivos CataluÃ±a"]
        BOCM_URL --> HOLIDAYS3["Verificar festivos Madrid"]
    end
    
    URL_GEN --> DRIVER_INIT["Inicializar WebDriver Firefox<br/>(Headless Mode)"]
    
    DRIVER_INIT --> URL_LOOP["Para cada URL generada"]
    
    URL_LOOP --> DOMAIN_CHECK{"Verificar dominio"}
    
    DOMAIN_CHECK -->|"boe.es"| BOE_SERVICE["scrape_boe()"]
    DOMAIN_CHECK -->|"dogc.gencat.cat"| DOGC_SERVICE["scrape_dogc()"]
    DOMAIN_CHECK -->|"dogv.gva.es"| DOGV_SERVICE["scrape_dogv()"]
    DOMAIN_CHECK -->|"sede.asturias.es"| BOPA_SERVICE["scrape_bopa()"]
    DOMAIN_CHECK -->|"bocm.es"| BOCM_SERVICE["scrape_bocm()"]
    DOMAIN_CHECK -->|"bop.diba.cat"| BOPDIBA_SERVICE["scrape_bopdiba()"]
    
    subgraph "Servicios de Scraping Especializados"
        BOE_SERVICE --> BOE_EXTRACT["Extraer de sumario<br/>CSS: li.dispo"]
        DOGC_SERVICE --> DOGC_EXTRACT["Extraer de destacados<br/>CSS: .destacat_text_cont"]
        DOGV_SERVICE --> DOGV_EXTRACT["Navegar iframes<br/>CSS: .imc--llistat"]
        BOPA_SERVICE --> BOPA_EXTRACT["Procesar listas<br/>HTML: dl/dt/dd"]
        BOCM_SERVICE --> BOCM_EXTRACT["ExtracciÃ³n paralela<br/>PDFs + tÃ­tulos"]
        BOPDIBA_SERVICE --> BOPDIBA_EXTRACT["NavegaciÃ³n multi-pÃ¡gina<br/>Sub-URLs"]
    end
    
    BOE_EXTRACT --> KEYWORD_FILTER1["Filtrar por keywords"]
    DOGC_EXTRACT --> KEYWORD_FILTER2["Filtrar por keywords"]
    DOGV_EXTRACT --> KEYWORD_FILTER3["Filtrar por keywords"]
    BOPA_EXTRACT --> KEYWORD_FILTER4["Filtrar por keywords"]
    BOCM_EXTRACT --> KEYWORD_FILTER5["Filtrar por keywords"]
    BOPDIBA_EXTRACT --> KEYWORD_FILTER6["Filtrar por keywords"]
    
    subgraph "Keywords de Filtrado"
        KEYWORDS["subvenciÃ³n, subvenciones, subvenciÃ³<br/>licitaciÃ³, licitaciÃ³n, contrato<br/>contracte, contractaciÃ³, contratos"]
    end
    
    KEYWORD_FILTER1 --> DATA_STRUCTURE["Estructura de Datos Estandarizada"]
    KEYWORD_FILTER2 --> DATA_STRUCTURE
    KEYWORD_FILTER3 --> DATA_STRUCTURE
    KEYWORD_FILTER4 --> DATA_STRUCTURE
    KEYWORD_FILTER5 --> DATA_STRUCTURE
    KEYWORD_FILTER6 --> DATA_STRUCTURE
    
    subgraph "Estructura de Datos"
        DATA_STRUCTURE --> FIELDS["url_base, title, link<br/>pdf_url, region, organism<br/>created_at"]
    end
    
    DATA_STRUCTURE --> SAVE_DB["Guardar en Base de Datos"]
    
    SAVE_DB --> SCRAPED_ITEM["Modelo ScrapedItem"]
    
    subgraph "Modelo de Datos"
        SCRAPED_ITEM --> REGIONS["Regiones:<br/>Nacional, Madrid, Asturias<br/>CataluÃ±a, Valencia"]
        SCRAPED_ITEM --> ORGANISMS["Organismos:<br/>BOE, BOCM, BOPA<br/>DOGC, DOGV, BOP DIBA"]
    end
    
    SCRAPED_ITEM --> API_ACCESS["API REST Disponible"]
    
    subgraph "Acceso a Datos"
        API_ACCESS --> FILTERS["Filtros disponibles:<br/>region, organism<br/>start_date, end_date"]
        API_ACCESS --> JSON_RESPONSE["Respuesta JSON"]
    end
    
    URL_LOOP --> MORE_URLS{"Â¿MÃ¡s URLs?"}
    MORE_URLS -->|"SÃ­"| URL_LOOP
    MORE_URLS -->|"No"| CLEANUP["Cerrar WebDriver"]
    
    CLEANUP --> SUCCESS["âœ… Scraping Completado"]
    
    subgraph "Manejo de Errores"
        ERROR_HANDLING["Manejo robusto de errores<br/>âš ï¸ Warnings<br/>âŒ Errores crÃ­ticos<br/>ContinuaciÃ³n parcial"]
    end
    
    BOE_SERVICE -.-> ERROR_HANDLING
    DOGC_SERVICE -.-> ERROR_HANDLING
    DOGV_SERVICE -.-> ERROR_HANDLING
    BOPA_SERVICE -.-> ERROR_HANDLING
    BOCM_SERVICE -.-> ERROR_HANDLING
    BOPDIBA_SERVICE -.-> ERROR_HANDLING
```

## Arquitectura del Sistema

### Componentes Principales

- **Orquestador Central**: [1](#5-0) 
- **Servicios de Scraping Regionales**: MÃ³dulos especializados para cada boletÃ­n
- **Modelo de Datos**: [2](#5-1) 
- **API REST**: [3](#5-2) 
- **Comando de GestiÃ³n**: [4](#5-3) 

### Servicios de Scraping Soportados

| BoletÃ­n | RegiÃ³n | CaracterÃ­sticas |
|---------|--------|-----------------|
| BOE | Nacional | ExtracciÃ³n de sumarios |
| DOGC | CataluÃ±a | Parsing DOM directo |
| DOGV | Valencia | Manejo de iframes |
| BOCM | Madrid | ExtracciÃ³n paralela |
| BOPA | Asturias | Procesamiento de listas |
| BOP DIBA | Barcelona | NavegaciÃ³n multi-pÃ¡gina |

## InstalaciÃ³n y ConfiguraciÃ³n

### InstalaciÃ³n con Docker

```bash
# Construir la imagen
docker build -t galio .

# Ejecutar el contenedor
docker run -d -p 8000:8000 galio
```

### InstalaciÃ³n Manual

```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar base de datos
python manage.py migrate

# Ejecutar scraping
python manage.py scrape
```

## Uso del Sistema

### Comando de Scraping

```bash
# Ejecutar scraping manual
python manage.py scrape
```

### API REST

```bash
# Obtener todos los elementos
GET /api/scraped-items/

# Filtrar por regiÃ³n
GET /api/scraped-items/?region=CataluÃ±a

# Filtrar por organismo
GET /api/scraped-items/?organism=BOE

# Filtrar por fechas
GET /api/scraped-items/?start_date=2025-01-01&end_date=2025-12-31
```

### Palabras Clave de Filtrado

El sistema busca automÃ¡ticamente contenido relacionado con: [5](#5-4) 

## Estructura del Proyecto

```
galio/
â”œâ”€â”€ webscraper_project/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ models.py              # Modelo de datos
â”‚   â”‚   â”œâ”€â”€ views.py               # API REST
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ scrape.py          # Orquestador principal
â”‚   â”‚   â”‚   â”œâ”€â”€ boe_service.py     # Scraper BOE
â”‚   â”‚   â”‚   â”œâ”€â”€ dogc_service.py    # Scraper DOGC
â”‚   â”‚   â”‚   â”œâ”€â”€ dogv_service.py    # Scraper DOGV
â”‚   â”‚   â”‚   â”œâ”€â”€ bocm_service.py    # Scraper BOCM
â”‚   â”‚   â”‚   â”œâ”€â”€ bopa_service.py    # Scraper BOPA
â”‚   â”‚   â”‚   â”œâ”€â”€ bopdiba_service.py # Scraper BOP DIBA
â”‚   â”‚   â”‚   â””â”€â”€ holidays.py        # GestiÃ³n de festivos
â”‚   â”‚   â””â”€â”€ management/commands/
â”‚   â”‚       â””â”€â”€ scrape.py          # Comando Django
â”‚   â”œâ”€â”€ Dockerfile                 # ConfiguraciÃ³n Docker
â”‚   â””â”€â”€ requirements.txt           # Dependencias Python
```

## Notes

Wiki pages you might want to explore:
- [System Architecture (rcellas/galio)](/wiki/rcellas/galio#2)
- [Regional Scrapers (rcellas/galio)](/wiki/rcellas/galio#3.2)
- [Docker Configuration (rcellas/galio)](/wiki/rcellas/galio#4.2)
