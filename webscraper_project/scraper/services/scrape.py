from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
import time

def scrape_multiple_websites(urls, keywords):
    # Configuraci√≥n del driver
    options = Options()
    options.add_argument('--headless')  
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    service = Service("/usr/local/bin/geckodriver")
    driver = webdriver.Firefox(service=service, options=options)

    scraped_data = []

    try:
        for url in urls:
            print(f"üîé Scraping URL: {url}")
            driver.get(url)

            # Esperar que la p√°gina cargue completamente
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )

            # Comprobar si hay iframes en la p√°gina
            iframes = driver.find_elements(By.TAG_NAME, "iframe")
            if iframes:
                print(f"üîÑ Se encontraron {len(iframes)} iframes.")
                
                # Mostrar los src de los iframes para analizar si son de otro dominio
                for i, iframe in enumerate(iframes):
                    print(f"üîç Iframe {i+1} src:", iframe.get_attribute("src"))
                
                # Cambiar al primer iframe
                driver.switch_to.frame(iframes[0])
                time.sleep(5)  # Espera adicional para que el contenido cargue

                # Verificar si hay m√°s iframes dentro del iframe
                nested_iframes = driver.find_elements(By.TAG_NAME, "iframe")
                if nested_iframes:
                    print(f"üîÑ Dentro del primer iframe hay {len(nested_iframes)} iframes adicionales.")

            # Esperar a que aparezcan los elementos con la clase deseada
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.CLASS_NAME, "imc--llistat"))
            )

            # Extraer los elementos
            sections = driver.find_elements(By.CLASS_NAME, "imc--llistat")

            # Capturar y mostrar el contenido del iframe para verificar si hay datos
            full_text = driver.find_element(By.TAG_NAME, "body").text.strip()
            print(f"üìú Texto encontrado en el iframe:\n{full_text}")

            # Filtrar y dividir el contenido en l√≠neas
            for section in sections:
                lines = section.text.strip().split("\n")  # Separar por l√≠neas
                for line in lines:
                    if any(kw.lower() in line.lower() for kw in keywords):
                        scraped_data.append({"text": line.strip()})

    except Exception as e:
        print("‚ùå Error al procesar las URLs:", e)
    finally:
        driver.quit()

    print("‚úÖ Scraped Data:", scraped_data)
    return scraped_data

# Definir URLs y palabras clave
urls = ["https://dogv.gva.es/es/inici"]
keywords = ["subvenci√≥n", "licitaci√≥n", "contratos"]

# Ejecutar la funci√≥n
scraped_data = scrape_multiple_websites(urls, keywords)
